{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.interpolate import interp1d\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "from fairness import *\n",
    "import shutil\n",
    "import time\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# ---- Quantile Function Class ----\n",
    "class EQF:\n",
    "    def __init__(self, sample_data):\n",
    "        self._calculate_eqf(sample_data)\n",
    "\n",
    "    def _calculate_eqf(self, sample_data):\n",
    "        \"\"\" Calculate the quantile function for the given sample data \"\"\"\n",
    "        sorted_data = np.sort(sample_data)\n",
    "        linspace = np.linspace(0, 1, num=len(sample_data))\n",
    "        self.interpolater = interp1d(linspace, sorted_data)\n",
    "        self.min_val = sorted_data[0]\n",
    "        self.max_val = sorted_data[-1]\n",
    "\n",
    "    def __call__(self, value_):\n",
    "        \"\"\" Interpolate a value based on the quantile function \"\"\"\n",
    "        try:\n",
    "            return self.interpolater(value_)\n",
    "        except ValueError:\n",
    "            if value_ < self.min_val:\n",
    "                return 0.0\n",
    "            elif value_ > self.max_val:\n",
    "                return 1.0\n",
    "            else:\n",
    "                raise ValueError('Error with input value')\n",
    "\n",
    "# ---- Fairness Objects Calculation ----\n",
    "def get_fairness_objects(sensitive_vector, predictions_s_0, predictions_s_1):\n",
    "    \"\"\"\n",
    "    Calculate ECDF (Empirical CDF) and EQF (Empirical Quantile Function) for sensitive and non-sensitive groups.\n",
    "    \n",
    "    Parameters:\n",
    "    - sensitive_vector: Array indicating sensitive attributes.\n",
    "    - predictions_s_0: Predictions for non-sensitive group.\n",
    "    - predictions_s_1: Predictions for sensitive group.\n",
    "    \n",
    "    Returns:\n",
    "    - pi_dict: Proportions of sensitive and non-sensitive groups.\n",
    "    - ecdf_dict: ECDF objects for both groups.\n",
    "    - eqf_dict: EQF objects for both groups.\n",
    "    \"\"\"\n",
    "    # Calculate CDF and quantile function for both groups\n",
    "    ecdf_dict = {\n",
    "        'p_non_sensitive': ECDF(predictions_s_0.reshape(-1,)),\n",
    "        'p_sensitive': ECDF(predictions_s_1.reshape(-1,))\n",
    "    }\n",
    "\n",
    "    eqf_dict = {\n",
    "        'p_non_sensitive': EQF(predictions_s_0.reshape(-1,)),\n",
    "        'p_sensitive': EQF(predictions_s_1.reshape(-1,))\n",
    "    }\n",
    "\n",
    "    # Calculate group proportions\n",
    "    pi_dict = {\n",
    "        'p_non_sensitive': sensitive_vector[sensitive_vector == 0.0].shape[0] / sensitive_vector.shape[0],\n",
    "        'p_sensitive': 1 - sensitive_vector[sensitive_vector == 0.0].shape[0] / sensitive_vector.shape[0]\n",
    "    }\n",
    "\n",
    "    return pi_dict, ecdf_dict, eqf_dict\n",
    "\n",
    "# ---- Data Reading Function ----\n",
    "def read_data(path_base, model, task, sens_dict):\n",
    "    \"\"\"\n",
    "    Read and combine train, validation, and test data for a specific task and model.\n",
    "    \n",
    "    Parameters:\n",
    "    - path_base: Base path for the data.\n",
    "    - model: Model name.\n",
    "    - task: Task name.\n",
    "    - sens_dict: Sensitive attribute dictionary.\n",
    "    \n",
    "    Returns:\n",
    "    - TRAIN: List containing training data, training scores, and training sensitive attributes.\n",
    "    - TEST: List containing test data, test scores, and test sensitive attributes.\n",
    "    \"\"\"\n",
    "    # Load train and validation datasets\n",
    "    df_train = pd.read_csv(f'{path_base}/DATA_VLDB/{task}/train.csv')\n",
    "    scores_train = pd.read_csv(f'{path_base}/VLDB_RES/{task}_{model}/score_train.csv')\n",
    "    sens_train = make_sens_vector(df_train, task, sens_dict)\n",
    "\n",
    "    df_valid = pd.read_csv(f'{path_base}/DATA_VLDB/{task}/valid.csv')\n",
    "    scores_valid = pd.read_csv(f'{path_base}/VLDB_RES/{task}_{model}/score_valid.csv')\n",
    "    sens_valid = make_sens_vector(df_valid, task, sens_dict)\n",
    "\n",
    "    # Combine train and validation datasets\n",
    "    df_train = pd.concat([df_train, df_valid])\n",
    "    scores_train = pd.concat([scores_train, scores_valid])\n",
    "    sens_train = np.concatenate((sens_train, sens_valid))\n",
    "\n",
    "    # Load test dataset\n",
    "    df_test = pd.read_csv(f'{path_base}/DATA_VLDB/{task}/test.csv')\n",
    "    scores_test = pd.read_csv(f'{path_base}/VLDB_RES/{task}_{model}/score_test.csv')\n",
    "    sens_test = make_sens_vector(df_test, task, sens_dict)\n",
    "\n",
    "    TRAIN = [df_train, scores_train, sens_train]\n",
    "    TEST = [df_test, scores_test, sens_test]\n",
    "\n",
    "    return TRAIN, TEST\n",
    "\n",
    "# ---- Fairness Estimation Function ----\n",
    "def get_fair_estimation(p_dict, ecdf_dict, eqf_dict, predictions_nonsensitive, predictions_sensitive, jitter=0.0001):\n",
    "    \"\"\"\n",
    "    Estimate fair probabilities for both sensitive and non-sensitive groups.\n",
    "    \n",
    "    Parameters:\n",
    "    - p_dict: Proportions of sensitive and non-sensitive groups.\n",
    "    - ecdf_dict: ECDF objects for both groups.\n",
    "    - eqf_dict: EQF objects for both groups.\n",
    "    - predictions_nonsensitive: Predictions for non-sensitive group.\n",
    "    - predictions_sensitive: Predictions for sensitive group.\n",
    "    - jitter: Small random noise added to avoid numerical issues.\n",
    "    \n",
    "    Returns:\n",
    "    - vals_1: Calibrated values for non-sensitive group.\n",
    "    - vals_2: Calibrated values for sensitive group.\n",
    "    \"\"\"\n",
    "    # Sample jitters\n",
    "    np.random.seed(int(time.time()))\n",
    "    jitter_matrix = np.random.uniform(-jitter, jitter, (predictions_sensitive.shape[0] + predictions_nonsensitive.shape[0]))\n",
    "\n",
    "    # ECDF-ified values\n",
    "    f_preds_nonsensitive = ecdf_dict['p_non_sensitive'](predictions_nonsensitive)\n",
    "    f_preds_sensitive = ecdf_dict['p_sensitive'](predictions_sensitive)\n",
    "\n",
    "    # Calculate calibrated values for non-sensitive group\n",
    "    vals_1 = np.zeros_like(predictions_nonsensitive)\n",
    "    vals_1 += p_dict['p_non_sensitive'] * eqf_dict['p_non_sensitive'](f_preds_nonsensitive)\n",
    "    vals_1 += p_dict['p_sensitive'] * eqf_dict['p_sensitive'](f_preds_nonsensitive)\n",
    "\n",
    "    # Calculate calibrated values for sensitive group\n",
    "    vals_2 = np.zeros_like(predictions_sensitive)\n",
    "    vals_2 += p_dict['p_non_sensitive'] * eqf_dict['p_non_sensitive'](f_preds_sensitive)\n",
    "    vals_2 += p_dict['p_sensitive'] * eqf_dict['p_sensitive'](f_preds_sensitive)\n",
    "\n",
    "    return vals_1, vals_2\n",
    "\n",
    "# ---- Fairness Metrics Calculation ----\n",
    "def _stats_(sens_array, prob_array, y_array):\n",
    "    \"\"\"\n",
    "    Calculate fairness metrics including Demographic Parity, Equal Opportunity, and Equal Opportunity Difference.\n",
    "    \n",
    "    Parameters:\n",
    "    - sens_array: Sensitive attribute array.\n",
    "    - prob_array: Probability predictions array.\n",
    "    - y_array: Ground truth labels array.\n",
    "    \n",
    "    Returns:\n",
    "    - DSP_EOD: Average Equal Opportunity Difference.\n",
    "    - DSP_EO: Average Equal Opportunity.\n",
    "    - DSP_DP: Average Demographic Parity.\n",
    "    - auc_all: AUC score for all data.\n",
    "    - Frac: Fraction of thresholds.\n",
    "    \"\"\"\n",
    "    prob_minor = prob_array[sens_array == 1]\n",
    "    prob_major = prob_array[sens_array == 0]\n",
    "\n",
    "    y_minor = y_array[sens_array == 1]\n",
    "    y_major = y_array[sens_array == 0]\n",
    "\n",
    "    DP, EO, EOD = [], [], []\n",
    "    PR_minor_all, TPR_minor_all = [], []\n",
    "    PR_major_all, TPR_major_all = [], []\n",
    "\n",
    "    # Calculate overall AUC\n",
    "    fpr, tpr, _ = roc_curve(y_array, prob_array)\n",
    "    auc_all = 100 * auc(fpr, tpr)\n",
    "\n",
    "    N = 500\n",
    "    for theta in np.linspace(0, 1, N):\n",
    "        # Calculate metrics for minor group\n",
    "        y_pred = np.array([1 if score > theta else 0 for score in prob_minor])\n",
    "        tn, fp, fn, tp = confusion_matrix(y_minor, y_pred).ravel()\n",
    "        tpr = tp / (tp + fn)\n",
    "        pr = (tp + fp) / len(y_minor)\n",
    "        fpr = fp / (fp + tn)\n",
    "        PR_minor_all.append(pr)\n",
    "        TPR_minor_all.append(tpr)\n",
    "\n",
    "        # Calculate metrics for major group\n",
    "        y_pred = np.array([1 if score > theta else 0 for score in prob_major])\n",
    "        tn, fp, fn, tp = confusion_matrix(y_major, y_pred).ravel()\n",
    "        tpr = tp / (tp + fn)\n",
    "        pr = (tp + fp) / len(y_major)\n",
    "        fpr = fp / (fp + tn)\n",
    "        PR_major_all.append(pr)\n",
    "        TPR_major_all.append(tpr)\n",
    "\n",
    "        # Calculate fairness disparities\n",
    "        EOD.append((np.abs(TPR_major_all[-1] - TPR_minor_all[-1]) + np.abs(fpr - fpr)))\n",
    "        EO.append(np.abs(TPR_major_all[-1] - TPR_minor_all[-1]))\n",
    "        DP.append(np.abs(PR_major_all[-1] - PR_minor_all[-1]))\n",
    "\n",
    "    DSP_EOD = 100 * np.average(EOD)\n",
    "    DSP_EO = 100 * np.average(EO)\n",
    "    DSP_DP = 100 * np.average(DP)\n",
    "    Frac = np.linspace(0, 1, N)\n",
    "\n",
    "    return DSP_EOD, DSP_EO, DSP_DP, auc_all, Frac\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: 0.21052631578947367\n",
      "Fodors-Zagat deepmatcher 2.86 5.56 5.81 100.0\n",
      "After:  EOD\n",
      "Fodors-Zagat deepmatcher 2.52 | eo 1.0 | eod 1.14 100.0\n",
      "\n",
      "Before: 0.21052631578947367\n",
      "Fodors-Zagat deepmatcher 2.86 5.56 5.81 100.0\n",
      "After:  EO\n",
      "Fodors-Zagat deepmatcher 2.52 | eo 1.0 | eod 1.14 100.0\n",
      "\n",
      "-------\n",
      "Before: 0.7894736842105263\n",
      "Fodors-Zagat DITTO 3.11 8.02 8.63 99.97278170930866\n",
      "After:  EOD\n",
      "Fodors-Zagat DITTO 1.0 | eo 6.38 | eod 7.79 99.93195427327164\n",
      "\n",
      "Before: 0.7894736842105263\n",
      "Fodors-Zagat DITTO 3.11 8.02 8.63 99.97278170930866\n",
      "After:  EO\n",
      "Fodors-Zagat DITTO 1.0 | eo 6.38 | eod 7.79 99.93195427327164\n",
      "\n",
      "-------\n",
      "Before: 0.05263157894736842\n",
      "Fodors-Zagat EMTransformer 3.13 0.0 0.09 100.0\n",
      "After:  EOD\n",
      "Fodors-Zagat EMTransformer 3.67 | eo 0.0 | eod 0.7 100.0\n",
      "\n",
      "Before: 0.05263157894736842\n",
      "Fodors-Zagat EMTransformer 3.13 0.0 0.09 100.0\n",
      "After:  EO\n",
      "Fodors-Zagat EMTransformer 3.67 | eo 0.0 | eod 0.7 100.0\n",
      "\n",
      "-------\n",
      "Before: 0.05263157894736842\n",
      "Fodors-Zagat HierGAT 2.3 7.02 7.02 100.0\n",
      "After:  EOD\n",
      "Fodors-Zagat HierGAT 2.82 | eo 1.95 | eod 1.95 100.0\n",
      "\n",
      "Before: 0.05263157894736842\n",
      "Fodors-Zagat HierGAT 2.3 7.02 7.02 100.0\n",
      "After:  EO\n",
      "Fodors-Zagat HierGAT 2.82 | eo 1.95 | eod 1.95 100.0\n",
      "\n",
      "-------\n",
      "Before: 0.3157894736842105\n",
      "Fodors-Zagat HierMatcher 2.95 0.51 1.47 100.0\n",
      "After:  EOD\n",
      "Fodors-Zagat HierMatcher 2.5 | eo 0.24 | eod 0.59 100.0\n",
      "\n",
      "Before: 0.2631578947368421\n",
      "Fodors-Zagat HierMatcher 2.95 0.51 1.47 100.0\n",
      "After:  EO\n",
      "Fodors-Zagat HierMatcher 3.02 | eo 0.24 | eod 1.01 100.0\n",
      "\n",
      "-------\n",
      "Before: 0.10526315789473684\n",
      "DBLP-GoogleScholar deepmatcher 6.13 11.49 11.72 98.41089489181923\n",
      "After:  EOD\n",
      "DBLP-GoogleScholar deepmatcher 5.43 | eo 7.99 | eod 8.38 98.40403357444629\n",
      "\n",
      "Before: 0.10526315789473684\n",
      "DBLP-GoogleScholar deepmatcher 6.13 11.49 11.72 98.41089489181923\n",
      "After:  EO\n",
      "DBLP-GoogleScholar deepmatcher 5.43 | eo 7.99 | eod 8.38 98.40403357444629\n",
      "\n",
      "-------\n",
      "Before: 0.05263157894736842\n",
      "DBLP-GoogleScholar DITTO 5.76 4.84 5.07 99.69593161887082\n",
      "After:  EOD\n",
      "DBLP-GoogleScholar DITTO 5.25 | eo 2.82 | eod 3.3 99.68764002688516\n",
      "\n",
      "Before: 0.05263157894736842\n",
      "DBLP-GoogleScholar DITTO 5.76 4.84 5.07 99.69593161887082\n",
      "After:  EO\n",
      "DBLP-GoogleScholar DITTO 5.25 | eo 2.82 | eod 3.3 99.68764002688516\n",
      "\n",
      "-------\n",
      "Before: 0.05263157894736842\n",
      "DBLP-GoogleScholar EMTransformer 5.17 3.96 4.51 98.71804386442197\n",
      "After:  EOD\n",
      "DBLP-GoogleScholar EMTransformer 5.12 | eo 3.71 | eod 4.29 98.7110025124824\n",
      "\n",
      "Before: 0.05263157894736842\n",
      "DBLP-GoogleScholar EMTransformer 5.17 3.96 4.51 98.71804386442197\n",
      "After:  EO\n",
      "DBLP-GoogleScholar EMTransformer 5.12 | eo 3.71 | eod 4.29 98.7110025124824\n",
      "\n",
      "-------\n",
      "Before: 0.10526315789473684\n",
      "DBLP-GoogleScholar HierGAT 5.25 3.34 3.83 99.71952614902061\n",
      "After:  EOD\n",
      "DBLP-GoogleScholar HierGAT 4.79 | eo 1.79 | eod 2.56 99.71600547305081\n",
      "\n",
      "Before: 0.10526315789473684\n",
      "DBLP-GoogleScholar HierGAT 5.25 3.34 3.83 99.71952614902061\n",
      "After:  EO\n",
      "DBLP-GoogleScholar HierGAT 4.79 | eo 1.79 | eod 2.56 99.71600547305081\n",
      "\n",
      "-------\n",
      "Before: 0.5789473684210527\n",
      "DBLP-GoogleScholar HierMatcher 5.41 4.4 5.28 99.34123351683523\n",
      "After:  EOD\n",
      "DBLP-GoogleScholar HierMatcher 4.56 | eo 3.34 | eod 3.56 99.34413407374215\n",
      "\n",
      "Before: 0.15789473684210525\n",
      "DBLP-GoogleScholar HierMatcher 5.41 4.4 5.28 99.34123351683523\n",
      "After:  EO\n",
      "DBLP-GoogleScholar HierMatcher 4.05 | eo 2.19 | eod 3.21 99.33199174241454\n",
      "\n",
      "-------\n",
      "Before: 0.7894736842105263\n",
      "iTunes-Amazon deepmatcher 13.76 17.87 23.71 96.97380307136405\n",
      "After:  EOD\n",
      "iTunes-Amazon deepmatcher 7.69 | eo 10.24 | eod 10.52 97.92231255645889\n",
      "\n",
      "Before: 0.7894736842105263\n",
      "iTunes-Amazon deepmatcher 13.76 17.87 23.71 96.97380307136405\n",
      "After:  EO\n",
      "iTunes-Amazon deepmatcher 7.69 | eo 10.24 | eod 10.52 97.92231255645889\n",
      "\n",
      "-------\n",
      "Before: 0.9473684210526315\n",
      "iTunes-Amazon DITTO 10.68 23.14 24.55 99.6386630532972\n",
      "After:  EOD\n",
      "iTunes-Amazon DITTO 12.37 | eo 24.59 | eod 25.15 99.59349593495934\n",
      "\n",
      "Before: 0.7368421052631579\n",
      "iTunes-Amazon DITTO 10.68 23.14 24.55 99.6386630532972\n",
      "After:  EO\n",
      "iTunes-Amazon DITTO 10.5 | eo 23.51 | eod 25.3 99.66124661246613\n",
      "\n",
      "-------\n",
      "Before: 0.05263157894736842\n",
      "iTunes-Amazon EMTransformer 10.76 0.0 5.6 99.9096657633243\n",
      "After:  EOD\n",
      "iTunes-Amazon EMTransformer 10.08 | eo 0.0 | eod 4.73 100.0\n",
      "\n",
      "Before: 0.05263157894736842\n",
      "iTunes-Amazon EMTransformer 10.76 0.0 5.6 99.9096657633243\n",
      "After:  EO\n",
      "iTunes-Amazon EMTransformer 10.08 | eo 0.0 | eod 4.73 100.0\n",
      "\n",
      "-------\n",
      "Before: 0.2631578947368421\n",
      "iTunes-Amazon HierGAT 13.21 29.74 30.17 98.46431797651309\n",
      "After:  EOD\n",
      "iTunes-Amazon HierGAT 12.08 | eo 24.9 | eod 25.08 99.29990966576334\n",
      "\n",
      "Before: 0.2631578947368421\n",
      "iTunes-Amazon HierGAT 13.21 29.74 30.17 98.46431797651309\n",
      "After:  EO\n",
      "iTunes-Amazon HierGAT 12.08 | eo 24.9 | eod 25.08 99.29990966576334\n",
      "\n",
      "-------\n",
      "Before: 0.6842105263157894\n",
      "iTunes-Amazon HierMatcher 9.13 5.47 9.42 98.69015356820235\n",
      "After:  EOD\n",
      "iTunes-Amazon HierMatcher 8.37 | eo 5.99 | eod 8.92 98.7353206865402\n",
      "\n",
      "Before: 0.47368421052631576\n",
      "iTunes-Amazon HierMatcher 9.13 5.47 9.42 98.69015356820235\n",
      "After:  EO\n",
      "iTunes-Amazon HierMatcher 7.81 | eo 4.71 | eod 7.36 98.69015356820235\n",
      "\n",
      "-------\n",
      "Before: 0.15789473684210525\n",
      "Walmart-Amazon deepmatcher 3.7 13.69 14.66 82.39514472038593\n",
      "After:  EOD\n",
      "Walmart-Amazon deepmatcher 2.76 | eo 12.1 | eod 12.34 82.3361008129355\n",
      "\n",
      "Before: 0.15789473684210525\n",
      "Walmart-Amazon deepmatcher 3.7 13.69 14.66 82.39514472038593\n",
      "After:  EO\n",
      "Walmart-Amazon deepmatcher 2.76 | eo 12.1 | eod 12.34 82.3361008129355\n",
      "\n",
      "-------\n",
      "Before: 0.47368421052631576\n",
      "Walmart-Amazon DITTO 1.9 4.58 5.61 96.88421252456672\n",
      "After:  EOD\n",
      "Walmart-Amazon DITTO 1.56 | eo 4.77 | eod 6.09 96.88895837055566\n",
      "\n",
      "Before: 0.7894736842105263\n",
      "Walmart-Amazon DITTO 1.9 4.58 5.61 96.88421252456672\n",
      "After:  EO\n",
      "Walmart-Amazon DITTO 1.59 | eo 4.79 | eod 6.08 96.88881878685011\n",
      "\n",
      "-------\n",
      "Before: 0.21052631578947367\n",
      "Walmart-Amazon EMTransformer 0.86 0.54 2.72 95.33650839735573\n",
      "After:  EOD\n",
      "Walmart-Amazon EMTransformer 0.58 | eo 0.59 | eod 3.06 95.32603961943899\n",
      "\n",
      "Before: 0.631578947368421\n",
      "Walmart-Amazon EMTransformer 0.86 0.54 2.72 95.33650839735573\n",
      "After:  EO\n",
      "Walmart-Amazon EMTransformer 0.95 | eo 0.6 | eod 2.7 95.33846256923351\n",
      "\n",
      "-------\n",
      "Before: 0.7368421052631579\n",
      "Walmart-Amazon HierGAT 1.66 12.7 15.12 96.76528720743256\n",
      "After:  EOD\n",
      "Walmart-Amazon HierGAT 1.65 | eo 12.44 | eod 14.77 96.74155797748794\n",
      "\n",
      "Before: 0.7894736842105263\n",
      "Walmart-Amazon HierGAT 1.66 12.7 15.12 96.76528720743256\n",
      "After:  EO\n",
      "Walmart-Amazon HierGAT 1.35 | eo 11.11 | eod 13.68 96.73625379667679\n",
      "\n",
      "-------\n",
      "Before: 0.42105263157894735\n",
      "Walmart-Amazon HierMatcher 2.87 9.78 10.4 94.52720207253886\n",
      "After:  EOD\n",
      "Walmart-Amazon HierMatcher 2.37 | eo 7.29 | eod 7.75 94.4994249151331\n",
      "\n",
      "Before: 0.42105263157894735\n",
      "Walmart-Amazon HierMatcher 2.87 9.78 10.4 94.52720207253886\n",
      "After:  EO\n",
      "Walmart-Amazon HierMatcher 2.37 | eo 7.29 | eod 7.75 94.4994249151331\n",
      "\n",
      "-------\n",
      "Before: 0.21052631578947367\n",
      "Amazon-Google deepmatcher 8.9 4.36 8.18 89.01923180699285\n",
      "After:  EOD\n",
      "Amazon-Google deepmatcher 8.87 | eo 5.14 | eod 8.82 88.96827768853024\n",
      "\n",
      "Before: 0.21052631578947367\n",
      "Amazon-Google deepmatcher 8.9 4.36 8.18 89.01923180699285\n",
      "After:  EO\n",
      "Amazon-Google deepmatcher 8.87 | eo 5.14 | eod 8.82 88.96827768853024\n",
      "\n",
      "-------\n",
      "Before: 0.05263157894736842\n",
      "Amazon-Google DITTO 5.73 5.15 6.77 96.71672830973462\n",
      "After:  EOD\n",
      "Amazon-Google DITTO 5.47 | eo 3.8 | eod 5.28 96.5665641357725\n",
      "\n",
      "Before: 0.05263157894736842\n",
      "Amazon-Google DITTO 5.73 5.15 6.77 96.71672830973462\n",
      "After:  EO\n",
      "Amazon-Google DITTO 5.47 | eo 3.8 | eod 5.28 96.5665641357725\n",
      "\n",
      "-------\n",
      "Before: 0.9473684210526315\n",
      "Amazon-Google EMTransformer 9.45 8.47 11.69 96.15374237763746\n",
      "After:  EOD\n",
      "Amazon-Google EMTransformer 8.0 | eo 3.6 | eod 5.57 95.9100758396533\n",
      "\n",
      "Before: 0.9473684210526315\n",
      "Amazon-Google EMTransformer 9.45 8.47 11.69 96.15374237763746\n",
      "After:  EO\n",
      "Amazon-Google EMTransformer 8.0 | eo 3.6 | eod 5.57 95.9100758396533\n",
      "\n",
      "-------\n",
      "Before: 0.6842105263157894\n",
      "Amazon-Google HierGAT 10.99 15.01 19.5 96.9261486988539\n",
      "After:  EOD\n",
      "Amazon-Google HierGAT 8.51 | eo 5.35 | eod 7.78 96.80379654881841\n",
      "\n",
      "Before: 0.631578947368421\n",
      "Amazon-Google HierGAT 10.99 15.01 19.5 96.9261486988539\n",
      "After:  EO\n",
      "Amazon-Google HierGAT 8.97 | eo 6.52 | eod 9.32 96.82911794373669\n",
      "\n",
      "-------\n",
      "Before: 0.7368421052631579\n",
      "Amazon-Google HierMatcher 9.04 21.97 26.24 90.05761655105997\n",
      "After:  EOD\n",
      "Amazon-Google HierMatcher 6.38 | eo 15.51 | eod 17.14 89.83179952096903\n",
      "\n",
      "Before: 0.2631578947368421\n",
      "Amazon-Google HierMatcher 9.04 21.97 26.24 90.05761655105997\n",
      "After:  EO\n",
      "Amazon-Google HierMatcher 7.88 | eo 16.13 | eod 19.28 89.99887921694624\n",
      "\n",
      "-------\n",
      "Before: 0.6842105263157894\n",
      "Beer deepmatcher 25.61 22.93 37.03 95.73283858998144\n",
      "After:  EOD\n",
      "Beer deepmatcher 21.56 | eo 16.36 | eod 26.89 95.64007421150278\n",
      "\n",
      "Before: 0.10526315789473684\n",
      "Beer deepmatcher 25.61 22.93 37.03 95.73283858998144\n",
      "After:  EO\n",
      "Beer deepmatcher 17.66 | eo 14.22 | eod 24.3 94.75881261595546\n",
      "\n",
      "-------\n",
      "Before: 0.05263157894736842\n",
      "Beer DITTO 41.62 0.3 29.72 98.51576994434137\n",
      "After:  EOD\n",
      "Beer DITTO 40.38 | eo 0.12 | eod 28.17 98.42300556586271\n",
      "\n",
      "Before: 0.05263157894736842\n",
      "Beer DITTO 41.62 0.3 29.72 98.51576994434137\n",
      "After:  EO\n",
      "Beer DITTO 40.38 | eo 0.12 | eod 28.17 98.42300556586271\n",
      "\n",
      "-------\n",
      "Before: 0.631578947368421\n",
      "Beer EMTransformer 30.71 0.0 14.12 97.1243042671614\n",
      "After:  EOD\n",
      "Beer EMTransformer 28.18 | eo 0.11 | eod 10.91 97.58812615955473\n",
      "\n",
      "Before: 0.05263157894736842\n",
      "Beer EMTransformer 30.71 0.0 14.12 97.1243042671614\n",
      "After:  EO\n",
      "Beer EMTransformer 33.77 | eo 0.0 | eod 18.49 97.77365491651207\n",
      "\n",
      "-------\n",
      "Before: 0.05263157894736842\n",
      "Beer HierGAT 34.16 44.0 56.81 98.9795918367347\n",
      "After:  EOD\n",
      "Beer HierGAT 30.82 | eo 19.83 | eod 31.85 99.48979591836734\n",
      "\n",
      "Before: 0.05263157894736842\n",
      "Beer HierGAT 34.16 44.0 56.81 98.9795918367347\n",
      "After:  EO\n",
      "Beer HierGAT 30.82 | eo 19.83 | eod 31.85 99.48979591836734\n",
      "\n",
      "-------\n",
      "Before: 0.8421052631578947\n",
      "Beer HierMatcher 31.75 16.42 36.08 96.75324675324674\n",
      "After:  EOD\n",
      "Beer HierMatcher 25.28 | eo 13.82 | eod 25.6 97.63450834879407\n",
      "\n",
      "Before: 0.8421052631578947\n",
      "Beer HierMatcher 31.75 16.42 36.08 96.75324675324674\n",
      "After:  EO\n",
      "Beer HierMatcher 25.28 | eo 13.82 | eod 25.6 97.63450834879407\n",
      "\n",
      "-------\n",
      "Before: 0.2631578947368421\n",
      "DBLP-ACM deepmatcher 3.62 1.56 1.78 99.57252718465139\n",
      "After:  EOD\n",
      "DBLP-ACM deepmatcher 3.47 | eo 1.47 | eod 1.62 99.57008511715264\n",
      "\n",
      "Before: 0.10526315789473684\n",
      "DBLP-ACM deepmatcher 3.62 1.56 1.78 99.57252718465139\n",
      "After:  EO\n",
      "DBLP-ACM deepmatcher 3.87 | eo 0.74 | eod 0.93 99.57102864323171\n",
      "\n",
      "-------\n",
      "Before: 0.21052631578947367\n",
      "DBLP-ACM DITTO 4.11 1.09 1.25 99.98867768705128\n",
      "After:  EOD\n",
      "DBLP-ACM DITTO 4.16 | eo 0.45 | eod 0.55 99.98634662262064\n",
      "\n",
      "Before: 0.21052631578947367\n",
      "DBLP-ACM DITTO 4.11 1.09 1.25 99.98867768705128\n",
      "After:  EO\n",
      "DBLP-ACM DITTO 4.16 | eo 0.45 | eod 0.55 99.98634662262064\n",
      "\n",
      "-------\n",
      "Before: 0.42105263157894735\n",
      "DBLP-ACM EMTransformer 4.68 0.42 0.87 99.96614406422194\n",
      "After:  EOD\n",
      "DBLP-ACM EMTransformer 4.53 | eo 0.39 | eod 0.68 99.9690301439932\n",
      "\n",
      "Before: 0.05263157894736842\n",
      "DBLP-ACM EMTransformer 4.68 0.42 0.87 99.96614406422194\n",
      "After:  EO\n",
      "DBLP-ACM EMTransformer 4.83 | eo 1.24 | eod 1.73 99.96847512865254\n",
      "\n",
      "-------\n",
      "Before: 0.10526315789473684\n",
      "DBLP-ACM HierGAT 4.37 0.44 0.65 99.98778966250626\n",
      "After:  EOD\n",
      "DBLP-ACM HierGAT 4.54 | eo 1.22 | eod 1.42 99.98740115176783\n",
      "\n",
      "Before: 0.15789473684210525\n",
      "DBLP-ACM HierGAT 4.37 0.44 0.65 99.98778966250626\n",
      "After:  EO\n",
      "DBLP-ACM HierGAT 4.5 | eo 1.19 | eod 1.36 99.98762315790408\n",
      "\n",
      "-------\n",
      "Before: 0.42105263157894735\n",
      "DBLP-ACM HierMatcher 3.89 1.02 1.69 99.75956735444169\n",
      "After:  EOD\n",
      "DBLP-ACM HierMatcher 3.87 | eo 0.81 | eod 1.38 99.75856832682855\n",
      "\n",
      "Before: 0.3157894736842105\n",
      "DBLP-ACM HierMatcher 3.89 1.02 1.69 99.75956735444169\n",
      "After:  EO\n",
      "DBLP-ACM HierMatcher 3.93 | eo 0.79 | eod 1.42 99.75856832682855\n",
      "\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from fairness import *\n",
    "import pickle\n",
    "\n",
    "\n",
    "with open('saved_params/sens_attr_dict_valid.pkl', 'rb') as file:\n",
    "    sens_attr_dict_valid = pickle.load(file)\n",
    "\n",
    "with open('saved_params/sens_attr_dict_train.pkl', 'rb') as file:\n",
    "    sens_attr_dict_train = pickle.load(file)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "RES = {}\n",
    "\n",
    "result_dict = {}\n",
    "path_base = os.getcwd()\n",
    "\n",
    "tasks = [ 'Fodors-Zagat','DBLP-GoogleScholar', 'iTunes-Amazon', 'Walmart-Amazon', 'Amazon-Google','Beer','DBLP-ACM']\n",
    "models = ['deepmatcher', 'DITTO', 'EMTransformer', 'HierGAT','HierMatcher']\n",
    "\n",
    "\n",
    "# tasks= ['iTunes-Amazon']\n",
    "# models = ['HierGAT']\n",
    "\n",
    "\n",
    "plots_res = {}\n",
    "\n",
    "RES = {}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for task in tasks:\n",
    "    RES[task] = {}\n",
    "    plots_res[task] = {}\n",
    "    for model in models:\n",
    "        RES[task][model] = {\n",
    "            'EOD_min':{},\n",
    "            'EO_min':{},\n",
    "            }\n",
    "        \n",
    "        plots_res[task][model] = {\n",
    "            'EOD_min':{},\n",
    "            'EO_min':{},\n",
    "            }\n",
    "\n",
    "        for rpt in ['EOD','EO']:\n",
    "                \n",
    "            tmp_all = []\n",
    "            other = []\n",
    "            frac = []   \n",
    "            for TH in np.linspace(0,1,20):\n",
    "                try:\n",
    "                \n",
    "\n",
    "                    \n",
    "\n",
    "                \n",
    "                    # # df_valid = pd.read_csv(path_base +'/DATA_VLDB/'+ task  + '/valid.csv')\n",
    "                    # scores_valid = pd.read_csv(path_base+'/VLDB_RES/'+task+'_'+model+'/score_valid.csv')\n",
    "                    # sens_valid = sens_attr_dict_valid[task]\n",
    "                    \n",
    "                    scores_valid = pd.concat([\n",
    "                        pd.read_csv(path_base+'/VLDB_RES/'+task+'_'+model+'/score_train.csv'),\n",
    "                        pd.read_csv(path_base+'/VLDB_RES/'+task+'_'+model+'/score_valid.csv')])\n",
    "\n",
    "                    sens_valid = np.concatenate((\n",
    "                        sens_attr_dict_train[task],\n",
    "                        sens_attr_dict_valid[task] ))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    for x in list(scores_valid.columns):\n",
    "                        if len(np.unique(scores_valid[x])) >2:  \n",
    "                            prob_valid = scores_valid[x]\n",
    "                        else: \n",
    "                            y_valid = scores_valid[x]\n",
    "\n",
    "                    \n",
    "                    jitter = 0\n",
    "                    prob_valid2 = prob_valid + np.random.uniform(-jitter, jitter, prob_valid.shape)\n",
    "\n",
    "\n",
    "\n",
    "                    prob_valid2_ = prob_valid2[prob_valid2 > TH]\n",
    "                    sens_valid_ = sens_valid[prob_valid2 > TH]\n",
    "\n",
    "                    p1_pos, e1_pos, q1_pos = get_fairness_objects(\n",
    "                    sens_valid_, \n",
    "                    np.array(prob_valid2_[sens_valid_ == 0]),  # non-sensitive = 0\n",
    "                    np.array(prob_valid2_[sens_valid_ == 1])   # sensitive = 1\n",
    "                    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    prob_valid2_ = prob_valid2[prob_valid2 <= TH]\n",
    "                    sens_valid_ = sens_valid[prob_valid2 <= TH]\n",
    "\n",
    "                    p1_neg, e1_neg, q1_neg = get_fairness_objects(\n",
    "                    sens_valid_, \n",
    "                    np.array(prob_valid2_[sens_valid_ == 0]),  # non-sensitive = 0\n",
    "                    np.array(prob_valid2_[sens_valid_ == 1])   # sensitive = 1\n",
    "                    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    CALIBRATED = []\n",
    "                    for idx, pnt in enumerate(prob_valid):\n",
    "                        if sens_valid[idx] ==1:\n",
    "                            in_0 = (np.array([])).reshape(-1,)\n",
    "                            in_1 = (np.array([pnt])).reshape(-1,)\n",
    "                        else: \n",
    "                            in_0 = (np.array([pnt])).reshape(-1,)\n",
    "                            in_1 = (np.array([])).reshape(-1,)\n",
    "\n",
    "                        if pnt > TH:\n",
    "                            fair_nonsensitive, fair_sensitive = get_fair_estimation(\n",
    "                                p1_pos, e1_pos, q1_pos, \n",
    "                                in_0, in_1, \n",
    "                                jitter= jitter)\n",
    "                            \n",
    "\n",
    "                        else:\n",
    "                            fair_nonsensitive, fair_sensitive = get_fair_estimation(\n",
    "                                p1_neg, e1_neg, q1_neg, \n",
    "                                in_0, in_1, \n",
    "                                jitter= jitter)\n",
    "                        \n",
    "                        if list(fair_sensitive) ==[]:\n",
    "                            CALIBRATED.append(list(fair_nonsensitive)[0])\n",
    "                        else:\n",
    "                            CALIBRATED.append(list(fair_sensitive)[0])\n",
    "\n",
    "                    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    pred_fair = pd.DataFrame(prob_valid.copy())\n",
    "                    pred_fair['calibrated'] = CALIBRATED\n",
    "\n",
    "                    if (np.sum(pred_fair['calibrated'] < 0) + np.sum(pred_fair['calibrated'] > 1)) > 0 :\n",
    "                        min_val = pred_fair['calibrated'].min()\n",
    "                        pred_fair['calibrated'] = pred_fair['calibrated']  - min_val\n",
    "                        max_val = pred_fair['calibrated'].max()\n",
    "                        pred_fair['calibrated'] = pred_fair['calibrated'] / max_val\n",
    "\n",
    "\n",
    "                    DSP_EOD, DSP_EO, DSP_DP, auc_all, Frac = _stats_(sens_valid,pred_fair['calibrated'], y_valid)\n",
    "\n",
    "                    if rpt == 'EO':\n",
    "                        tmp_all.append(DSP_EO)\n",
    "                        other.append(DSP_EOD)\n",
    "                    else:\n",
    "                        tmp_all.append(DSP_EOD)\n",
    "                        other.append(DSP_EO)\n",
    "\n",
    "                    frac.append(TH)\n",
    "\n",
    "                except:\n",
    "                    # print(TH, end =' ')\n",
    "                    continue\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "                    \n",
    "\n",
    "            import numpy as np\n",
    "            import pandas as pd\n",
    "            from fairness import *\n",
    "            import pickle\n",
    "\n",
    "\n",
    "            with open('saved_params/sens_attr_dict_test.pkl', 'rb') as file:\n",
    "                sens_attr_dict_test = pickle.load(file)\n",
    "\n",
    "            df_test = pd.read_csv(path_base +'/DATA_VLDB/'+ task  + '/test.csv')\n",
    "            scores_test = pd.read_csv(path_base+'/VLDB_RES/'+task+'_'+model+'/score_test.csv')\n",
    "            sens_test = sens_attr_dict_test[task]\n",
    "\n",
    "            result_dict = {}\n",
    "            path_base = os.getcwd()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                \n",
    "            df_test = pd.read_csv(path_base +'/DATA_VLDB/'+ task  + '/test.csv')\n",
    "            scores_test = pd.read_csv(path_base+'/VLDB_RES/'+task+'_'+model+'/score_test.csv')\n",
    "            sens_test = sens_attr_dict_test[task]\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            for x in list(scores_test.columns):\n",
    "                if len(np.unique(scores_test[x])) >2:  \n",
    "                    prob_test = scores_test[x]\n",
    "                else: \n",
    "                    y_test = scores_test[x]\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            TH = frac[np.argmin(tmp_all)]\n",
    "\n",
    "            print('Before:', TH)\n",
    "            DSP_EOD, DSP_EO, DSP_DP, auc_all, Frac = _stats_(sens_test,prob_test, y_test)\n",
    "            print(task, model, round(DSP_DP,2), round(DSP_EO,2), round(DSP_EOD,2), auc_all)\n",
    "\n",
    "\n",
    "            jitter = 0\n",
    "            prob_test2 = prob_test + np.random.uniform(-jitter, jitter, prob_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "            prob_test2_ = prob_test2[prob_test2 > TH]\n",
    "            sens_test_ = sens_test[prob_test2 > TH]\n",
    "\n",
    "            p1_pos, e1_pos, q1_pos = get_fairness_objects(\n",
    "            sens_test_, \n",
    "            np.array(prob_test2_[sens_test_ == 0]),  # non-sensitive = 0\n",
    "            np.array(prob_test2_[sens_test_ == 1])   # sensitive = 1\n",
    "         )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            prob_test2_ = prob_test2[prob_test2 <= TH]\n",
    "            sens_test_ = sens_test[prob_test2 <= TH]\n",
    "\n",
    "            p1_neg, e1_neg, q1_neg = get_fairness_objects(\n",
    "            sens_test_, \n",
    "            np.array(prob_test2_[sens_test_ == 0]),  # non-sensitive = 0\n",
    "            np.array(prob_test2_[sens_test_ == 1])   # sensitive = 1\n",
    "         )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            CALIBRATED = []\n",
    "            for idx, pnt in enumerate(prob_test):\n",
    "                if sens_test[idx] ==1:\n",
    "                    in_0 = (np.array([])).reshape(-1,)\n",
    "                    in_1 = (np.array([pnt])).reshape(-1,)\n",
    "                else: \n",
    "                    in_0 = (np.array([pnt])).reshape(-1,)\n",
    "                    in_1 = (np.array([])).reshape(-1,)\n",
    "\n",
    "                if pnt > TH:\n",
    "                    fair_nonsensitive, fair_sensitive = get_fair_estimation(\n",
    "                        p1_pos, e1_pos, q1_pos, \n",
    "                        in_0, in_1, \n",
    "                        jitter= jitter)\n",
    "                    \n",
    "\n",
    "                else:\n",
    "                    fair_nonsensitive, fair_sensitive = get_fair_estimation(\n",
    "                        p1_neg, e1_neg, q1_neg, \n",
    "                        in_0, in_1, \n",
    "                        jitter= jitter)\n",
    "                \n",
    "                if list(fair_sensitive) ==[]:\n",
    "                    CALIBRATED.append(list(fair_nonsensitive)[0])\n",
    "                else:\n",
    "                    CALIBRATED.append(list(fair_sensitive)[0])\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "            # print(rpt, np.min\n",
    "            # (tmp_all), other[np.argmin(tmp_all)])\n",
    "\n",
    "\n",
    "            pred_fair = pd.DataFrame(prob_test.copy())\n",
    "            pred_fair['calibrated'] = CALIBRATED\n",
    "\n",
    "            if (np.sum(pred_fair['calibrated'] < 0) + np.sum(pred_fair['calibrated'] > 1)) > 0 :\n",
    "                min_val = pred_fair['calibrated'].min()\n",
    "                pred_fair['calibrated'] = pred_fair['calibrated']  - min_val\n",
    "                max_val = pred_fair['calibrated'].max()\n",
    "                pred_fair['calibrated'] = pred_fair['calibrated'] / max_val\n",
    "\n",
    "\n",
    "            DSP_EOD2, DSP_EO2, DSP_DP2, auc_all2, Frac = _stats_(sens_test,pred_fair['calibrated'], y_test)\n",
    "\n",
    "            print('After: ', rpt)\n",
    "            print(task, model, round(DSP_DP2,2), '| eo',round(DSP_EO2,2), '| eod', round(DSP_EOD2,2), auc_all2)\n",
    "\n",
    "\n",
    "\n",
    "            print()\n",
    "            if rpt == 'EO':\n",
    "                K = 'EO_min'\n",
    "            else:\n",
    "                K = 'EOD_min'\n",
    "\n",
    "            RES[task][model][K] = {\n",
    "                'before':{\n",
    "                    'DP':DSP_DP,\n",
    "                    'EO':DSP_EO,\n",
    "                    'EOD': DSP_EOD,\n",
    "                    'auc':auc_all\n",
    "                },\n",
    "                'after':{\n",
    "                    'gamma':TH,\n",
    "                    'DP':DSP_DP2,\n",
    "                    'EO':DSP_EO2,\n",
    "                    'EOD': DSP_EOD2,\n",
    "                    'auc':auc_all2\n",
    "                }\n",
    "            }\n",
    "\n",
    "            plots_res[task][model][K] = {'TH':frac, 'tmp_all':tmp_all}\n",
    "\n",
    "        print('-------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump the object to a pickle file\n",
    "with open('repair_label_wise_result.pkl', 'wb') as file:\n",
    "    pickle.dump(RES, file)\n",
    "\n",
    "# Dump the object to a pickle file\n",
    "with open('repair_label_wise_result_plot.pkl', 'wb') as file:\n",
    "    pickle.dump(plots_res, file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
