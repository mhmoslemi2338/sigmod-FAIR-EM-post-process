{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from fairness import *\n",
    "import shutil\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "path_base = os.getcwd()\n",
    "\n",
    "SENS_train = {}\n",
    "SENS_valid = {}\n",
    "\n",
    "\n",
    "tasks = ['Fodors-Zagat', 'DBLP-GoogleScholar', 'iTunes-Amazon', 'Walmart-Amazon', 'Amazon-Google','Beer','DBLP-ACM']\n",
    "\n",
    "for task in tasks:\n",
    "    print(task, 'TRAIN')\n",
    "    df_train = pd.read_csv(path_base +'/DATA_VLDB/'+ task  + '/train.csv')\n",
    "    sens_train = make_sens_vector(df_train, task, sens_dict) \n",
    "\n",
    "    print(task, 'valid')\n",
    "    df_valid = pd.read_csv(path_base+'/DATA_VLDB/' + task  + '/valid.csv')\n",
    "    sens_valid = make_sens_vector(df_valid, task, sens_dict) \n",
    "\n",
    "    SENS_train[task] = sens_train\n",
    "    SENS_valid[task] = sens_valid\n",
    "    print('DONE')\n",
    "    print()\n",
    "\n",
    "with open('sens_attr_dict_train.pkl', 'wb') as file:\n",
    "    pickle.dump(SENS_train, file)\n",
    "\n",
    "\n",
    "with open('sens_attr_dict_valid.pkl', 'wb') as file:\n",
    "    pickle.dump(SENS_valid, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from fairness import *\n",
    "import shutil\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "path_base = os.getcwd()\n",
    "\n",
    "SENS_test = {}\n",
    "\n",
    "\n",
    "tasks = ['Fodors-Zagat', 'DBLP-GoogleScholar', 'iTunes-Amazon', 'Walmart-Amazon', 'Amazon-Google','Beer','DBLP-ACM']\n",
    "\n",
    "for task in tasks:\n",
    "    print(task, 'TEST')\n",
    "    df_test = pd.read_csv(path_base +'/DATA_VLDB/'+ task  + '/test.csv')\n",
    "    sens_test = make_sens_vector(df_test, task, sens_dict) \n",
    "\n",
    "    SENS_test[task] = sens_test\n",
    "    print('DONE')\n",
    "    print()\n",
    "\n",
    "with open('sens_attr_dict_test.pkl', 'wb') as file:\n",
    "    pickle.dump(SENS_test, file)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
